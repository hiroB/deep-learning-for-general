# 📜 歴史

##### [ENIAC (エニアック)](https://ja.wikipedia.org/wiki/ENIAC)
1946年にアメリカで開発された世界初のコンピュータ。
17,468本もの真空管を使った巨大な電子計算機。

設計したのはペンシルベニア大学の[ジョン・モークリー](https://ja.wikipedia.org/wiki/%E3%82%B8%E3%83%A7%E3%83%B3%E3%83%BB%E3%83%A2%E3%83%BC%E3%82%AF%E3%83%AA%E3%83%BC)と[ジョン・プレスパー・エッカート](https://ja.wikipedia.org/wiki/%E3%82%B8%E3%83%A7%E3%83%B3%E3%83%BB%E3%83%97%E3%83%AC%E3%82%B9%E3%83%91%E3%83%BC%E3%83%BB%E3%82%A8%E3%83%83%E3%82%AB%E3%83%BC%E3%83%88)
[マーヴィン・ミンスキー](https://ja.wikipedia.org/wiki/%E3%83%9E%E3%83%BC%E3%83%93%E3%83%B3%E3%83%BB%E3%83%9F%E3%83%B3%E3%82%B9%E3%82%AD%E3%83%BC)、[ジョン・マッカーシー](https://ja.wikipedia.org/wiki/%E3%82%B8%E3%83%A7%E3%83%B3%E3%83%BB%E3%83%9E%E3%83%83%E3%82%AB%E3%83%BC%E3%82%B7%E3%83%BC)、[アレン・ニューウェル](https://ja.wikipedia.org/wiki/%E3%82%A2%E3%83%AC%E3%83%B3%E3%83%BB%E3%83%8B%E3%83%A5%E3%83%BC%E3%82%A6%E3%82%A7%E3%83%AB)、[ハーバート・サイモン](https://ja.wikipedia.org/wiki/%E3%83%8F%E3%83%BC%E3%83%90%E3%83%BC%E3%83%88%E3%83%BB%E3%82%B5%E3%82%A4%E3%83%A2%E3%83%B3)など、後に人工知能の研究で重要な役割を果たす著名な研究者たちも参加した。

##### [ダートマス会議](http://www.dartmouth.edu/~ai50/homepage.html)

1956年7月から8月にかけて開催された[ジョン・マッカーシー](https://ja.wikipedia.org/wiki/%E3%82%B8%E3%83%A7%E3%83%B3%E3%83%BB%E3%83%9E%E3%83%83%E3%82%AB%E3%83%BC%E3%82%B7%E3%83%BC)が主催した会議。
史上初めて「人工知能（Artificial Intelligence）」という用語が使われた。

##### [ロジック・セオリスト](https://ja.wikipedia.org/wiki/Logic_Theorist)
1955年から1956年にかけてアレン・ニューウェル、ハーバート・サイモン、J・C・ショーが開発した世界初の人工知能プログラム。
コンピュータを使って数学の定理が自動的に証明することが実現可能であることを示した。

## 人工知能のレベル
##### 人工知能 (AI: Artificial Intelligence)
コンピュータによる知的な情報処理システムを設計、または実現するための研究分野。研究者によって定義は異なる。

##### 機械学習
人工知能を実現するための手法のうち特に、人間の学習能力、予測能力をコンピュータで実現しようとする技法や手法の総称

##### ディーブラーニング（深層学習）
ディープニューラルネットワークを用いて学習を行う、機械学習のアルゴリズムの1つ。

##### 特化型人工知能
特定のタスクでのみ成果を出せる人工知能。弱い人工知能。現在の技術ではこちらしか実現できていない。

##### 汎用人工知能
人間と同等の知能を持もった人工知能。強い人工知能。

##### レベル1 (マーケティング用 AI)
「人工知能搭載X」のような家電など

##### レベル2 (弱い AI)
チェスプログラム、将棋マシーン

##### レベル3 (強い AI)
人間の知能を目指そうとするもの

##### レベル4 (強い AI を超えうるもの)
表現学習、深層学習

##### AI効果
人工知能で何か新しいことを実現したときに、その原理がわかってしまうと、「それは単純な自動化であって知能とは関係ない」と結論づける人間の心理的効果

##### [ELIZA効果](https://ja.wikipedia.org/wiki/ELIZA%E5%8A%B9%E6%9E%9C)
人間は、相手が高度な知能を持った存在ではなくとも、自分に適切に反応してくれれば、本物の人間と対話しているように錯覚する傾向があること

## 第1次AIブーム（1956 - 1974: 探索・推論による人工知能）

冷戦下のアメリカで、自然言語処理による機械翻訳の研究に注力されていたことが有名。しかし当時は、実用的な機械翻訳を行うことはきわめて困難であると結論された。

##### [チューリングテスト](https://ja.wikipedia.org/wiki/%E3%83%81%E3%83%A5%E3%83%BC%E3%83%AA%E3%83%B3%E3%82%B0%E3%83%BB%E3%83%86%E3%82%B9%E3%83%88)(1950)
ある機械が人工知能かどうか判定するためのテスト。「機械が知能をもっているか」という問いから、「機械が知能をもっている存在として人間が認知できるか」という問題に置き換えている。

##### [ローブナー賞](https://ja.wikipedia.org/wiki/%E3%83%AD%E3%83%BC%E3%83%96%E3%83%8A%E3%83%BC%E8%B3%9E)
人工知能として最も人間に近いと判定された会話ボットに対して毎年授与される賞。

競技の形式は標準的なチューリングテスト。

##### 推論
自分がもつ知識と知識を組み合わせることで新しい知識を見つけ出す

##### 探索
推論により導き出せる結果を、いかに早くおこなえるかを求めた手法。問題をうまく表現することができれば、効率的に解を見つけ出すことができる

##### 人工知能を考える視点
環境・状態・行動をコード化できるとそのタスクは人工知能で解くことができる。推論・探索ではこの3要素を機械が理解できる形に書けないと解くことができない。

##### トイ・プロブレム
迷路やオセロなど、機械にときやすい簡単な問題

##### [ELIZA (イライザ)](https://ja.wikipedia.org/wiki/ELIZA)
1966年に発表された自然言語処理プログラム。[人工無脳](https://ja.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%84%A1%E8%84%B3)の起源となった。

##### [PARRY](https://ja.wikipedia.org/wiki/PARRY)
1972年に開発された ELIZA と共に有名な初期の会話ボット。ELIZA との最初の会話記録は [RFC439](https://tools.ietf.org/html/rfc439) に残されている。

##### [BFS (幅優先探索)](https://ja.wikipedia.org/wiki/%E5%B9%85%E5%84%AA%E5%85%88%E6%8E%A2%E7%B4%A2)
隣接するノードを優先して探索するアルゴリズム

##### [DFS (深さ優先探索)](https://ja.wikipedia.org/wiki/%E6%B7%B1%E3%81%95%E5%84%AA%E5%85%88%E6%8E%A2%E7%B4%A2)
目的のノードが見つかるか子のないノードに行き着くまで、深く探索するアルゴリズム

##### ハノイの塔

##### ロボットの行動計画（プランニング）

##### STRIPS

##### SHRDLU

##### [Mini-Max法](https://ja.wikipedia.org/wiki/%E3%83%9F%E3%83%8B%E3%83%9E%E3%83%83%E3%82%AF%E3%82%B9%E6%B3%95)
想定される最大の損害が最小になるように決断を行う戦略

##### [モンテカルロ法](https://ja.wikipedia.org/wiki/%E3%83%A2%E3%83%B3%E3%83%86%E3%82%AB%E3%83%AB%E3%83%AD%E6%B3%95)
シミュレーションや数値計算を乱数を用いて行う手法の総称。ランダム法とも呼ばれる。

## 第2次AIブーム（1980 - 1987: 知識表現による人工知能）

エキスパートシステムにより問題を解く人工知能が台頭。しかし専門家の知識の定式化は難しく（知識獲得のボトルネック）、複雑な問題が解けるようにならなかった。

##### エキスパートシステム
専門家の知識をそのまま人工知能に移植する事により、さまざまな問題を解決するアイディア

##### [ナレッジエンジニア](https://www.weblio.jp/content/%E3%83%8A%E3%83%AC%E3%83%83%E3%82%B8%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2)
人工知能（AI）を応用したシステム構築を専門とする技術者

##### [MYCIN (マイシン)](https://ja.wikipedia.org/wiki/Mycin)
1970年代初めに開発された抗生物質を処方するAI

##### [DENDRAL](https://ja.wikipedia.org/wiki/Dendral)
1960年代の[エドワード・ファイゲンバウム](https://ja.wikipedia.org/wiki/%E3%82%A8%E3%83%89%E3%83%AF%E3%83%BC%E3%83%89%E3%83%BB%E3%83%95%E3%82%A1%E3%82%A4%E3%82%B2%E3%83%B3%E3%83%90%E3%82%A6%E3%83%A0)が開発した未知の有機化合物の特定するエキスパートシステム

##### 知識ベース
if-then 文よって記述できる知識の集まり

##### 推論エンジン
知識ベースを用いて推論を行うプログラム

##### 第五世代コンピュータ
通商産業省（現経済産業省）が1982年に立ち上げた国家プロジェクト。

[第五世代コンピュータ・プロジェクト最終評価報告書](https://www.jipdec.or.jp/archives/publications/J0005062)（平成5年3月30日 電子計算機基礎技術開発推進委員会）

##### 人工無能
会話ボットやチャットボットなど、主にテキストを用いた会話をシミュレートするコンピュータプログラム

##### 意味ネットワーク
もともと認知心理学における長期記憶の構造モデルとして考案されたもの。
現在は、人工知能においても重要な知識表現の一つ。

「概念」をラベルの付いたノードで表し、概念間の関係をラベルの付いたリンク（矢印）で結んだネットワークで表す。

  - is-a 関係

  上位概念と下位概念の関係を表す。継承関係（ex. 動物は生物である。哺乳類は動物である。）

  - part-of 関係

  全体と部分の関係を表す。属性（ex. 目は頭部の一部である。肉球は足の一部である。）

##### [Cycプロジェクト](https://ja.wikipedia.org/wiki/Cyc%E3%83%97%E3%83%AD%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88)
1984年にスタートした、すべての一般常識をコンピュータに取り込むプロジェクト

##### オントロジー
AI におけるオントロジーとは「概念化の明示的な仕様」（Tom Gruber）であり、共通の概念の体系（語彙とその定義）とそれらの関係のことを指す。

本体は哲学用語で「存在論」という意味だが、人工知能の用語としては、[トム・グルーバー](https://en.wikipedia.org/wiki/Tom_Gruber)による「概念の明示的な仕様」という定義が広く受け入れられている。

##### ヘビーウェイトオントロジー
対象世界の知識をどのように記述すべきかを哲学的にしっかり考えて行うもの。

哲学的な考察が必要になるため、人間が関わる傾向が強く、時間とコストがかかる（ex. Cycプロジェクト）

##### ライトウェイトオントロジー
効率を重視し、とにかくコンピュータにデータを読み込ませてできる限り自動的に行うもの。

完全に正しいものでなくても使えるものであればいいという考えから、その構成要素の分類関係の正当性については深く考察は行わない傾向にある。
コンピュータで概念間の関係性を自動でみつける取り組みがある。（ex. ウェブマイニング、データマイニング、ワトソン）

##### [ワトソン](https://ja.wikipedia.org/wiki/%E3%83%AF%E3%83%88%E3%82%BD%E3%83%B3_(%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF))
IBM が開発した質問応答システム。

2011年にアメリカのクイズ番組で歴代の人間チャンピオンに勝利した。
ウィキペディアの情報をもとにライトウェイト・オントロジーを生成して、それを解答につかっている。

##### [Deep Blue](https://ja.wikipedia.org/wiki/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%BB%E3%83%96%E3%83%AB%E3%83%BC_(%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF))
IBMが開発したチェス専用のスーパーコンピュータ。

1996年、チェスの世界チャンピオンであるガルリ・カスパロフに勝利した。


## 第3次AIブーム（2000 -: 機械学習と深層学習による人工知能）

##### 機械学習

##### ディーブラーニング

##### 特徴量
データをよく表す特徴を数値で示したもの（ex. 「人間」を表す特徴量としては、身長、体重、年齢、性別など）

##### 特徴量エンジニアリング
モデルが認識しやすいような「特徴」をデータから新しく作ること。

たった1つの成分だけが 1、残りの成分が 0 という特徴量（ベクトル）に変換する。この形のことを [one-hot-encoding](https://ja.wikipedia.org/wiki/One-hot) と呼ぶ。

##### 内部表現
ディープラーニングにより自動的に獲得された特徴量

#### レコメンデーショーンシステム

顧客の購買行動の促進のために、機械学習によってその顧客が好みそうな商品を推定し推薦するシステム。

##### 協調フィルタリング
ユーザーの購買履歴をともにおすすめを提示

##### 内容ベースフィルタリング
アイテムの特徴をもとにおすすめを提示


[人工知能](https://ja.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%9F%A5%E8%83%BD) > [機械学習](https://ja.wikipedia.org/wiki/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92) > [ニューラルネットワーク](https://ja.wikipedia.org/wiki/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF) > [ディープラーニング](https://ja.wikipedia.org/wiki/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0)

##### [モラベックのパラドックス](https://ja.wikipedia.org/wiki/%E3%83%A2%E3%83%A9%E3%83%99%E3%83%83%E3%82%AF%E3%81%AE%E3%83%91%E3%83%A9%E3%83%89%E3%83%83%E3%82%AF%E3%82%B9)
子供のできることほど人工知能には難しい

### [ILSVRC (Large Scale Visual Recognition Challenge)](http://www.image-net.org/challenges/LSVRC/)
2010年から始まった ImageNet データセットを用いた画像認識の競技会。

2012年、トロント大学の[ジェフリー・ヒントン](https://ja.wikipedia.org/wiki/%E3%82%B8%E3%82%A7%E3%83%95%E3%83%AA%E3%83%BC%E3%83%BB%E3%83%92%E3%83%B3%E3%83%88%E3%83%B3)教授のチームが [AlexNet](https://en.wikipedia.org/wiki/AlexNet) と呼ばれる畳み込みニューラルネットワーク(CNN)で[2位以下を10%上回る正答率](http://image-net.org/challenges/LSVRC/2012/results.html)を出す。これがきっかけとなり、ディーブラーニングが脚光を浴びる。

[ImageNet](http://www.image-net.org/index) は、画像に写っている物体名（クラス名）を付与したデータベース。

[Overview - ImageNet](http://www.image-net.org/about-overview)

#### 2012年

ディープラーニングが脚光を浴びるきっかけになった年。

結果: http://image-net.org/challenges/LSVRC/2012/results

##### AlexNet

畳み込み層とプーリング層を深くしていく構造


#### 2014年

層を深くしていくと計算量が非常に大きくなって学習が進まなくなるおちう問題があったが、小さなサイズの畳み込みフィルター（1x1, 3x3）を差し込んで次元（計算量）を削減するという工夫が取られるようになった。

結果: http://image-net.org/challenges/LSVRC/2014/results

##### GoogLeNet
2014年のコンペで1位になったアーキテクチャ。

このアーキテクチャは通常の入力層から出力層まで縦一直線な構造ではなく、インセプション構造と呼ばれる横にも層が広がる構成にすることで、並列計算を行いやすくしている。このため、Inceptionモデルとも呼ばれる。

ref: https://arxiv.org/pdf/1409.4842.pdf

##### VGG
2014年のILSVRCで2位になった、オックスフォード大学のVGGチームのネットワーク

#### 2015年

結果: http://image-net.org/challenges/LSVRC/2015/results

##### ResNet (Residual Network)
2015年のILSVRCで優勝したネットワーク。

それまでのネットワークでは層を深くしすぎると性能が落ちるという問題があったが、それを「スキップ構造」によって解決し、152層もの深さ(前年優勝のGoogLeNetでも22層)を実現した。

以下のような理由で学習がうまくいっている。
- 層が深くなっても、層を飛び越える部分は伝播しやすくなる
- 様々な形のネットワークのアンサンブル学習になっている

ref: https://arxiv.org/pdf/1512.03385v1.pdf
