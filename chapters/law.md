# ⚖️ 法律・倫理・現行の議論

##### プライバシーバイ・デザイン（PdD）
プライバシー侵害の予防を指向し、仕様段階から検討するプロセス。

##### セキュリティ・バイ・デザイン
##### バリュー・センシティブ・デザイン

##### 倫理的に調和された設計
2016年に学術団体である IEEE が出したレポート。

自律システムの透明性やデータプライバシー処理などの標準規格（P7000）を目指している。

資料: https://confit.atlas.jp/guide/event-img/jsai2018/3H1-OS-25a-05/public/pdf?type=in

##### データの利用条件
  1. 著作権法
  2. 不正競争防止法
  3. 個人情報保護法
  4. 個別の契約
  5. その他の理由により、データの利用に制約がかかっている場合

##### 個人情報
- 個人識別符号
  - 個人を特定できる識別子。免許証番号とか。
- オンライン識別子
  - IPアドレスやCookieなど。
- パーソナルデータ
  - 購買履歴、位置情報など
- 要配慮情報（機微情報）
  - 人種、病歴など
  - 取得・利用、第三者への提供いずれも禁止
- 匿名加工情報
  - 特定の個人を完全に識別できないよう加工した個人情報
  - 本人の同意なく、第三者に提供できる
- 仮名加工情報
  - 他の情報と照合しない限り、特定の個人を識別できない、ように加工した個人情報

##### 取扱注意なデータ
- 個人情報
- 営業秘密
- 限定提供データ
- 通信の秘密

##### オプトイン
事前に許可した顧客のみ個人情報を取り扱える。

##### オプトアウト
本人が拒否しない限り、個人情報の第三者提供に同意しているものとみなす。
拒否した顧客には利用を止める必要がある。
事前に個人情報保護委員会に届け出が必要。

##### PDS(Personal Data Store)
個人が自らの意思で、自らのデータを蓄積・管理・活用するための仕組み。第三者への提供に係る制御機能を有する。

##### 情報銀行
PDSなどのシステムを活用して、個人のデータを管理する。

個人の指示またはあらかじめ決められた条件に基づき、個人にかわり妥当性を判断し、第三者に提供する。

##### オープン・イノベーション
組織外の知識・技術を取り込もうとする動き

##### [AI・データの利用に関する契約ガイドライン](https://www.meti.go.jp/press/2018/06/20180615001/20180615001.html)

1. アセスメント段階
2. PoC段階
3. 開発段階
4. 追加学習段階

##### データセットの偏り

##### プライバシーリスクを低減するデータ加工

##### 協調フィルタリング

##### [FAT (Fairness, Accountability, and Transparency)](https://www.fatml.org/)
AIの公平性、説明可能性、透明性

##### 敵対的な攻撃

##### 知的財産法

##### GDPR
欧州経済領域（EEA）内の個人データの保護を規定する法律であり、データ管理者及びデータ処理者に対し、個人データの取り扱いや移転に係る義務を定めている。
2016年4月に制定され、2018年5月に施行された。

##### アルゴリズムバイアス
Google Photos がアフリカ系の女性に「ゴリラ」とラベル付をしてしまった事件

##### インセンティブ設計

##### クライシスマネージメント  
危機管理対応

##### エスカレーション

##### 透明性レポート
  - [Twitter](https://transparency.twitter.com/ja.html)
  - [Google](https://transparencyreport.google.com/?hl=ja)
  - [Facebook](https://transparency.facebook.com/)

###### 倫理問題

- AI自身のリスク
- 人間がAIを利用して引き起こすリスク
- 既存の社会秩序への負の影響
- 法律・社会の在り方

##### [PAI(Partnership on AI)](https://www.partnershiponai.org/)
2016年9月に、Amazon、Google、DeepMind(Google)、Facebook、IBM、Microsoft が設立した、将来のAI研究と開発のための非営利団体。

##### [アシロマAI原則](https://futureoflife.org/ai-principles-japanese/)
人類の存続の危機を回避することを目的とする組織、[Future of Life Institute（FLI）](https://futureoflife.org/) が、2017年2月にアメリカのアシロマで発表した、人工知能（AI）の研究課題、倫理と価値、長期的な課題を23にまとめたガイドライン。

##### ELSI
元は生命科学の用語

- Ethics（倫理）
- Legal（法律）
- Social（社会）
- Issues（課題）

##### [AIネットワーク社会推進会議](https://www.soumu.go.jp/main_sosiki/kenkyu/ai_network/index.html)

##### [人間中心のAI社会原則検討会議](https://www8.cao.go.jp/cstp/tyousakai/humanai/index.html)
2018年5月に内閣府のCSTIの下に設置された会議。
AIに関する倫理や中長期的な研究開発・利活用などについて、産学民官のマルチステークホルダーによる幅広い視野からの調査・検討が行われ、2019年3月に「人間中心のAI社会原則」が決定された。

##### AI戦略2019

##### XAI (説明可能なAI)
ディーブラーニングを使う機械学習では、特徴抽出も自動化されているため、与えられたデータに対する推論過程そのものが「見えない」状態となる。
しかし、自動運転や医療診断など、推論結果が重大な問題を引き起こす可能性があるものに関しては、原因究明が要請される。

  - Black Box Explanation（解釈可能モデルの抽出）
    - AIをブラックボックスとして同等の解釈可能なモデルの生成を目指す
  - Model Output Explanation（出力に対する説明の生成）
    - AIの出力に対し、予測の根拠を説明できることを目指す 
  - Model Inspection（ブラックボックスの中身を検査）
    - ブラックボックスの中身を説明できることを目指す
  - Transparent Box Design（透明性のある学習器の設計）
    - AIの学習過程や構造を人間が解釈しやすくモデル化することを目指す

## 各国の政策
各国とその国の経済成長戦略の組み合わせ。

| 国 | 政策 |
| --- | --- |
| 日本 | 新産業構造ビジョン |
| 英国 | RAS 2020 戦略 |
| ドイツ | デジタル戦略2025 |
| 中国 | インターネットプラスAI3年行動実施法案 |


## アメリカ
##### Preparing for the Future of Artificial Intelligence（人工知能の未来に備えて）
2016年にホワイトハウスが出した人工知能に関する報告書。
AIの現状； AIの現在及び将来の潜在的な用途； AIの進展が引き起こす社会政策・公共政策上の問題を取り上げているほか、連邦省庁等が取るべき具体的な取組みについて提言を行っている。

概要: https://nedodcweb.org/reports/report2016/2016-10-24/

##### THE NATIONAL ARTIFICIAL INTELLIGENCE RESEARCH AND DEVELOPMENT STRATEGIC PLAN（人工知能（AI）研究開発国家戦略計画）
上記報告書とともにホワイトハウスが公表した報告書。

判断結果の理由をユーザーに説明できる AI プログラムを開発することが必要であることを主張した。

概要: https://nedodcweb.org/report/AI%20Research%20Development%20Plan.pdf

##### Artificial Intelligence, Automation, and the Economy（AI、自動化、そして経済）
2016年12月にホワイトハウスが公開したAI（人工知能）と経済に関するレポート。

AI の普及が最大で 300 万件越えの雇用に影響を与える可能性があることを説いている。

ニュース記事: https://japan.zdnet.com/article/35094155/

## 日本
##### 人材不足
経済産業省が定めた先端 IT 人材がどのような人材需給状況にあるかの推定によると,2020 年には需給ギャップが広がり人材の不足は4.8万人に及ぶと言われている。

資料: https://www.meti.go.jp/committee/kenkyukai/shoujo/daiyoji_sangyo_skill/pdf/001_06_00.pdf

##### 知的財産
収集・生成したデータや学習済みのモデルは、一定の条件を満たせば、知的財産として保護される。
関連する法令として、特許権法、著作権法、不正競争防止法などがある。

##### 個人情報
個人情報を取り扱う際には、**利用目的をできる限り特定**しなければならない（個人情報保護法15条1項）

当初予定されていなかった個人情報の取扱をするのであれば、**原則として事前に本人の同意が必要**になる（同16条1項）
加えて、その利用目的を本人に通知し、または公表しなければならない（同18条1項）

##### 著作権法
著作権法47条の７によって、著作者にモダンで記録や翻案をしても適法となっている。2018年の著作権法改正によって、学習データを第三者と共有したり、一般に販売したり、ネット上で公開するとことも、一定の条件下で適法となっている（改正著作権法30条4）

「情報解析を行うために著作物を複製すること」が、営利・非営利を問わず適法とされていて（47条7）、世界的に見ても先進的な規定を言われている。

論文や写真など著作物にあたるデータを利用したい場合は、著作権者から許諾を得ることが原則。ただし、学習用データの作成については一定の要件のもと自由に行える例外規定もある（著作権法第47条7、改正著作権法第30条4）

もっとも、著作権法による制約をクリアした場合でも、著作権とは別の観点からデータ利用に制約がかかることがある。
- 営業秘密にあたるデータ（不正競争防止法2条6）
- 限定利用データ（改正不正競争防止法2条7）
- 購買履歴や位置情報などのパーソナルデータ
- ライセンス契約で利用条件が指定されているデータ
- 「通信の秘密」にあたるメールの内容（憲法21条2、電気通信事業法4条）

#### AI・データの利用に関する契約ガイドライン
2018年に経済産業省が公表した、民間事業者等が、データの利用等に関する契約やAI技術を利用するソフトウェアの開発・利用に関する契約を締結するガイドライン。

概要: https://www.meti.go.jp/press/2018/06/20180615001/20180615001.html

## EU

##### GDPR（EU一般データ保護法則）
2018年5月に運用が開始された。

データ主体の権利・利益を強化した規則になっている、

日本に対しても域外適用されるため、EU向けにもサービスを提供する日本企業も法的規制を受ける場合がある。

##### AIに関する倫理ガイドライン
2019年に欧州委員会が発表した。下記の7つの項目をAIが満たすべき要件としている。

- 人間の活動と監視
- 堅固性と安全性
- プライバシーとデータのガバナンス
- 透明性
- 多様性・被差別・公平性
- 社会・環境福祉
- 説明責任

