# ⚖️ 法律・倫理・現行の議論

##### プライバシーバイ・デザイン

##### 倫理的に調和された設計
2016年にIEEEが出したレポート

##### データの利用条件
  1. 著作権法
  2. 不正競争防止法
  3. 個人情報保護法
  4. 個別の契約
  5. その他の理由により、データの利用に制約がかかっている場合

##### 日本の著作権法
著作権法47条の７によって、著作者にモダンで記録や翻案をしても適法となっている。2018年の著作権法改正によって、学習データを第三者と共有したり、一般に販売したり、ネット上で公開するとことも、一定の条件下で適法となっている（改正著作権法30条4）

##### オープン・イノベーション

##### [AI・データの利用に関する契約ガイドライン](https://www.meti.go.jp/press/2018/06/20180615001/20180615001.html)

##### データセットの偏り

##### プライバシーリスクを低減するデータ加工

##### 協調フィルタリング

##### [FAT (Fairness, Accountability, and Transparency)](https://www.fatml.org/)
AIの公平性、説明可能性、透明性

##### 敵対的な攻撃

##### 知的財産法

##### GDPR
欧州経済領域（EEA）内の個人データの保護を規定する法律であり、データ管理者及びデータ処理者に対し、個人データの取り扱いや移転に係る義務を定めている。
2016年4月に制定され、2018年5月に施行された。

##### アルゴリズムバイアス
Google Photos がアフリカ系の女性に「ゴリラ」とラベル付をしてしまった事件

##### インセンティブ設計

##### クライシスマネージメント  
危機管理対応

##### エスカレーション

##### 透明性レポート
  - [Twitter](https://transparency.twitter.com/ja.html)
  - [Google](https://transparencyreport.google.com/?hl=ja)
  - [Facebook](https://transparency.facebook.com/)

##### [PAI(Partnership on AI)](https://www.partnershiponai.org/)

##### [アシロマAI原則](https://futureoflife.org/ai-principles-japanese/)
人類の存続の危機を回避することを目的とする組織、[Future of Life Institute（FLI）](https://futureoflife.org/) が、2017年2月にアメリカのアシロマで発表した、人工知能（AI）の研究課題、倫理と価値、長期的な課題を23にまとめたガイドライン。

##### [AIネットワーク社会推進会議](https://www.soumu.go.jp/main_sosiki/kenkyu/ai_network/index.html)

##### [人間中心のAI社会原則検討会議](https://www8.cao.go.jp/cstp/tyousakai/humanai/index.html)
2018年5月に内閣府のCSTIの下に設置された会議。
AIに関する倫理や中長期的な研究開発・利活用などについて、産学民官のマルチステークホルダーによる幅広い視野からの調査・検討が行われ、2019年3月に「人間中心のAI社会原則」が決定された。

##### XAI (説明可能なAI)
ディーブラーニングを使う機械学習では、特徴抽出も自動化されているため、与えられたデータに対する推論過程そのものが「見えない」状態となる。
しかし、自動運転や医療診断など、推論結果が重大な問題を引き起こす可能性があるものに関しては、原因究明が要請される。
