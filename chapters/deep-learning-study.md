# 🔬 ディープラーニングの研究分野

## 画像認識分野

##### [AlexNet (アレックスネット)](https://en.wikipedia.org/wiki/AlexNet)
2012年、ILSVRC で従来の SVM に替わりディープラーニングに基づくモデルで初めて優勝した。

筆頭開発者であるアレックス・クリジェフスキーの名前から、「アレックスネット」と呼ばれている。

### R-CNN

![](https://media.geeksforgeeks.org/wp-content/uploads/20200219161502/RCNN1.png)
https://www.geeksforgeeks.org/r-cnn-vs-fast-r-cnn-vs-faster-r-cnn-ml/

##### R-CNN（Region Convolutional Neural Network）
空間認識にすぐれている CNN を分割された領域ごとに適用するディープニューラルネットワーク。

関心領域（ROI）の切り出しには、HOG など CNN ではない従来の手法を用いる。ROI の画像切り出しの後に領域ごとに個別に CNN を呼びだす二段階のモデルのため、時間がかかっていた。

画像上の矩形領域（長方形）、バウンディングボックスで、領域を切り出す。

##### fast RCNN
領域の切り出しと切り出した領域の物体認識を同時に行うモデル。

##### faster RCNN
fast RCNN を更に改良したモデル。
ほぼ実時間（1秒あたり16フレーム）で入力画像から関心領域の切り出しと認識がきるようになった。

##### YOLO (You Only Look Once)
領域の切り出しと認識を同時に行う CNN。

##### SSD (Single Shot Detector)
領域の切り出しと認識を同時に行う CNN。

### セマンティックセグメンテーション・インスタンスセグメンテーション

##### セマンティックセグメンテーション
R-CNN のような矩形領域を切り出すのではなく、より詳細な領域分割を得るモデル。
各画素がどのカテゴリーに属するかを求める手法。

同じカテゴリーに属する複数の物体が同一ラベルとして扱われる。

##### インスタンスセグメンテーション
個々の物体ごとにカテゴリーを認識させる。

##### FCN (完全畳み込みネットワーク)
セマンティックセグメンテーションを実現するネットワークモデル。

FCN とは文字通りすべての層が畳み込み層であるモデル。

入力画像の画素数だけ出力層が必要、つまり出力層には、縦画素数 x 横画素数 x カテゴリー数の出力ニューロンが用意される。

##### アンサンプリング
最終出力層で入力層と同じ解像度を得るために、下位層のプーリング層の情報を用いて詳細な解像度を得る手法。

CNN では畳み込み演算によって畳み込みのカーネル幅（受容野）だけ近傍の入力刺激を加えて計算することになるため、上位層では下位層にくらべて受容野が大きくなり、その影響で画像サイズは小さくなる。

##### Mask RCNN

## 自然言語処理

### 単語の意味を表すベクトル空間モデル

##### [word2vec](https://ja.wikipedia.org/wiki/Word2vec)
文章中の単語は、記号の集まりとして表現できる。この記号をベクトルとして表現することで、ベクトル間の距離や関係として単語の意味を表現するモデル。

Googleのトマス・ミコロフ率いる研究者チームによって2013年に作成された。

単語の意味をベクトル空間の中に表現したと考えられるため、「単語埋め込みモデル（word embedding models）」とも呼ばれる。

word2vec には以下の2つの手法がある。

##### スキップグラム（Skip-gram）
ある単語を与えて周辺の単語を予測するモデル。

##### CBOW
周辺の単語を与えてある単語を予測するモデル。

##### [セマンティックウェブ](https://ja.wikipedia.org/wiki/%E3%82%BB%E3%83%9E%E3%83%B3%E3%83%86%E3%82%A3%E3%83%83%E3%82%AF%E3%83%BB%E3%82%A6%E3%82%A7%E3%83%96)
情報リソースに意味を付与することで、コンピュータで高度な意味処理を実現する

##### [意味ネットワーク](https://ja.wikipedia.org/wiki/%E6%84%8F%E5%91%B3%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF)
単語同士の意味関係をネットワークによって表現する

##### [統計的自然言語処理](https://ja.wikipedia.org/wiki/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86#%E7%B5%B1%E8%A8%88%E7%9A%84%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86)
言語処理に確率的あるいは統計的手法を用いる技術

##### [言語モデル](https://ja.wikipedia.org/wiki/%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB)
自然言語処理などにおいて、文の品詞や統語構造、単語と単語、文書と文書などの関係性について定式化したもの。

### 文章の意味表現

##### fastText
2013年に word2vec を提案したトマス・ミコロフらによって開発されたモデル。

word2vec との変更点は、単語の表現に文字情報も含めること。文字データを援用することで訓練データには存在しない単語（Out Of Vocabulary: OOV）を表現することを可能にした。

##### ELMo
[アレンインスティチュート](https://ja.wikipedia.org/wiki/%E3%82%A2%E3%83%AC%E3%83%B3%E8%84%B3%E7%A7%91%E5%AD%A6%E7%A0%94%E7%A9%B6%E6%89%80) によって開発された文章表現を得るモデル。

2層の双方向リカレントネットワーク言語モデルの内部状態から計算される。fastText と同じく OOV であっても意味表現を得ることが可能。

##### 普遍埋め込みモデル
1対多のマルチタスク学習により、複数課題間に共通の普遍的な文章埋め込み表現を学習するモデル。

##### [TF-IDF](https://ja.wikipedia.org/wiki/Tf-idf)
文書内に出現する単語について，以下の２つの情報から，その単語の重要度を算出する手法である．
- 単語の出現頻度 (TF値)
- 単語の逆文書頻度 (IDF値)

### その他の応用

##### NIC (ニューラル画像脚注付け)
画像認識をする CNN と言語モデルとしてのリカレントニューラルネットワークを組み合わせて、画像に脚注をつける手法。

##### NTM (ニューラルチューリングマシン)
チーリングマシンをニューラルネットワークで実現する試み。

## 音声認識

##### WaveNet
音声合成と音声認識の両者を行うことができるモデル。

## 強化学習

##### DQN (Deep Q-Network)
DeepMind が考案した、Q学習の行動価値関数を、深い構造を持ったニューラルネットワークで置き換えたモデル。

##### MCTS (モンテカルロ木探索)
モンテカルロ法を使った木の探索。

ヒューリスティクス（途中で不要な探索をやめ、ある程度の高確率で良い手を導ける）な探索アルゴリズムである。

##### AlphaGo Zero
2017年10月に発表された、棋譜を全く必要としない、完全に自己対局（セルフプレイ）のみで学習していく碁のプログラム。
従来の AlphaGo を超える強さとなった。
