# :globe_with_meridians: ディープラーニング

ディープニューラルネットワークを用いた機械学習の手法。  
2010年代に脚光を浴びたが、アルゴリズム自体は1960年代にはすでに考案されていた。 

ニューラルネットワークを3層より多層にしても学習精度が上がらない壁にぶつかったが、自己符号化器の研究などを足場にして、層を深くしても学習することが可能となった。

人工知能の大家[マービン・ミンスキー](https://ja.wikipedia.org/wiki/%E3%83%9E%E3%83%BC%E3%83%93%E3%83%B3%E3%83%BB%E3%83%9F%E3%83%B3%E3%82%B9%E3%82%AD%E3%83%BC)によって、特定の条件下の単純パーセプトロンでは直線で分離できるような単純な問題しか解けないということが指摘されたが、バックプロパゲーション（誤差逆伝播法）で克服できることが示された。

「深い関数を使った最小二乗法」  
「シグモイド関数など活性化関数を使って非線形性を入れ、多層に構成した関数を使った、損失関数の最小化」

## 変遷
- 1958年  
パーセプトロン

- 1969年  
パーセプトロンの性能と限界に関する論文  
（冬の時代が始まる）

- 1986年  
バックプロパゲーション（誤差逆伝播法）  
（第二次 AI ブーム）

- 2006年  
自己符号化器  
（第3次 AI プームのきかっけ）

- 2012年  
ILSVRC でトロント大学の SuperVision が優勝

- 2017年  
AlphaGo が人間のプロ囲碁棋士を破る

## ニューラルネットワーク

人間の神経回路（ニューロン）の構造をモデル化したネットワーク。

- ニューロン  
単純な数値予測ができ予測器。ニューラルネットワークの最小単位  
重みが乗算された入力を受け取り、それらを総和して出力する

- ニューラルネットワーク  
ニューロンをたくさんつなげててきる予測器。入力が行わる層を「入力層」、出力される層を「出力層」、それ以外の層を「中間層」または「隠れ層」と呼ぶ。  
また、入力層の各ノードが隠れ層のすべてのノードと結合しているような層を「全結合層」と呼ぶ。  
人間の脳を模倣したモデルではなく、「人間の脳の仕組みの一部」を模倣している。

- [ネオコグニトロン](https://ja.wikipedia.org/wiki/%E3%83%8D%E3%82%AA%E3%82%B3%E3%82%B0%E3%83%8B%E3%83%88%E3%83%AD%E3%83%B3)  
1982年に福島邦彦氏によって発表された、畳み込みニューラルネットワークの発想の基となったネットワークモデル

- 宝くじ仮説  
「ランダムに初期化された密なニューラルネットワークは、たまたまうまく学習ができるように初期化されたサブネットワークが含まれており、このサブネットは、学習が進むにつれて他のサブネットよりも優れているので早く学習が進み、他の劣るサブネットの活性が抑制される」という仮説。  
この仮説を提唱した論文「[The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks](https://arxiv.org/abs/1803.03635)」は、2019年5月にはディープラーニングのカンファレンス ICLR 2019で [Best Paper Award](https://iclr.cc/Conferences/2019/Awards) に選ばれた。

ニューラルネットワークの設定（ハイパーパラメータ）を変えることによる出力結果の変化を直感的に確かめることができるサイト。

![スクリーンショット 2020-06-27 21 45 25](https://user-images.githubusercontent.com/5207601/85922615-bbf6cf00-b8bf-11ea-80a5-91a844d82d54.png)
[A Neural Network Playground](https://playground.tensorflow.org/)

### 学習の手順

1. ミニバッチ  
訓練データの中からランダムに一部のデータを選び出す。   
その選ばれたデータをミニバッチと言い、ここでは、そのミニバッチの損失関数の値を減らすことを目的とする。
1. 勾配算出  
ミニバッチの損失関数を減らすために、各重みパラメータの勾配を求める。  
勾配は、損失関数の値を最も減らす方向を示す。
1. パラメータの更新  
重みパラメータを勾配方向に微小量だけ更新する。（確率的勾配降下法）
1. 1 ~ 3 を繰り返す。


- [誤差逆伝播法（バックプロパゲーション）](https://ja.wikipedia.org/wiki/%E3%83%90%E3%83%83%E3%82%AF%E3%83%97%E3%83%AD%E3%83%91%E3%82%B2%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3)  
ニューラルネットワークの出力と正答データとの差（誤差）が後ろ（逆）のノードへと伝播するように計算を行い、その重みを調整する手法。

### 学習（イテレーション）の方法

- バッチ学習  
1回の学習ですべてのデータを読み込んで学習する。  
メモリの大きさが増加するが、すべてのデータを均等に扱える。  
また、計算時間は長くなるので、モデルの更新に時間がかかる。

- ミニバッチ学習  
1回の学習で「バッチサイズ」として設定した数のデータを読み込んで学習する。  
学習結果は最後に読み込んだデータに引っ張られるため、学習順序によって性能が変わるケースがある。

- オンライン学習  
1回の学習で1つのデータを読み込んで学習する。  
学習サイクルが速く、新しいデータが入るとすぐそのデータが学習されたモデルが手に入る。  
ミニバッチ学習と同様に、学習結果は最後に読み込んだデータに引っ張られるため、学習順序によって性能が変わるケースがある。

## 従来の機機械学習との違い

機械学習では、対象領域の知識に基づいて適切に手法を選択する必要があるが、ディーブラーニングでは、表現力の高い「深い関数」を用いるため、データと計算量されあれば精度が上がる。  
ディーブラーニングに適した学習データは、正規化されているものよりも、画像や音声そのもの、膨大なテキストなど。  
どうやてデータを集めるか、どうやってアノテーション（ラベルやメダデータを与えて学習データを整備）するかが課題となる。


## 用語

- [ノーフリーランチ定理](ノーフリーランチ定理)  
「あらゆる問題に対して万能なアルゴリズムは存在しない」という定理

- 単純パーセプトロン  
1958年にアメリカの心理学者[フランク・ローゼンブラット](https://ja.wikipedia.org/wiki/%E3%83%95%E3%83%A9%E3%83%B3%E3%82%AF%E3%83%BB%E3%83%AD%E3%83%BC%E3%82%BC%E3%83%B3%E3%83%96%E3%83%A9%E3%83%83%E3%83%88)が提案したニューラルネットワークの元祖のモデル

- 多層パーセプトロン


- オートエンコーダ  
2006年に発表され、今日のディーブラーニング隆盛のきっかけともなった技術。  
次元数を減らしたニューロン層を重ねていくことで特徴の圧縮を行うエンコーダと逆の構造を持つデコーダーを接続したもの。  
砂時計型の構造をもつニューラルネットワークで、入力側から半分をエンコーダ、残り半分をデコーダーと呼ぶ。  
入力層と出力層のノード数が等しく、中間層のノード数が入出力層よりが少ない。  
入力情報と同じ出力情報を再現するこを目指す（「正解ラベル」として「入力自身」を用いる）

- 次元削減  
オートエンコーダにおいて、隠れ層で特徴的な情報だけに次元を圧縮すること

- ディープオートエンコーダ  
オートエンコーダを順番に学習させ、それを積み重ねる手法。  
ディープニューラルネットワークのように一気にすべての層を学習するのではなく、**入力層に近い層から順番に学習されるという、逐次的な方法をとった。**  
事前学習とファインチューニングの工程で構成される。

- 事前学習  
オートエンコーダを順番に学習していく手法

- ファインチューニング  
最後にロジスティック回帰層（シグモイド関数あるいはソフトマックス関数による出力層）を足すことで、教師学習を実現する。  
これにより、ネットワーク全体は隠れ層が複数あるディープニューラルネットワークになる。  
事前学習を終え、ロジスティック回帰層を足したら、最後の仕上げとしてディープニューラルネットワーク全体で学習を行い重みを調整する。

## 活性化関数

入力信号の総和を出力信号に変換する関数。  
出力層で使用する活性化関数は、回帰問題では恒等関数、分類問題ではソフトマックス関数を一般的に利用する。

パーセプトロンとニューラルネットワークの主な違いは、活性化関数。  
パーセプトロンではステップ関数、ニューラルネットワークではシグモイド関数など非線形関数を用いる。

- ステップ関数  
微分できないのでニューラルネットワークの学習で実際に使われることはない

- [シグモイド関数](https://ja.wikipedia.org/wiki/%E3%82%B7%E3%82%B0%E3%83%A2%E3%82%A4%E3%83%89%E9%96%A2%E6%95%B0)  
入力を 0 ~ 1の間に値に変換する性質を持つ関数。  
ステップ関数と形が似ていて、なめらかなので微分できる関数として考案された

- [tanh (ハイパボリックタンジェント関数)](https://ja.wikipedia.org/wiki/%E5%8F%8C%E6%9B%B2%E7%B7%9A%E9%96%A2%E6%95%B0)  

- [ReLU関数](https://ja.wikipedia.org/wiki/%E6%AD%A3%E8%A6%8F%E5%8C%96%E7%B7%9A%E5%BD%A2%E9%96%A2%E6%95%B0)  
正則化機能を持たいない活性化関数で、勾配消失問題が起きにくく、最近の主流。  
入力が 0 を超えていればその入力をそのまま出力し、0 以下ならば 0 を出力する。  

- ソフトマックス関数  
出力を正規化して、確率として解釈する際に用いされる活性化関数。
分類問題の出力層付近で用いられることが一般的。

- Leaky ReLU関数  

- Parametric ReLU  

- Randomized ReLU  

## 学習の流れ

1. 教師データを用いて予測計算をする。その際の予測値を正解ラベルと比較して誤差を計算する。
1. 予測値は左から右へと順番に伝わる（順伝播）
1. 上記をいくつかの教師データについて繰り返し、誤差を足し合わせる
1. 累計された誤差が小さくなるように、勾配降下法を用いて各枝の重みを更新する。  
   枝の重みは右から左へと順番に更新される（誤差逆伝播法）
1. 上記を繰り返す

## 学習率の最適化

- [勾配降下法](https://ja.wikipedia.org/wiki/%E7%A2%BA%E7%8E%87%E7%9A%84%E5%8B%BE%E9%85%8D%E9%99%8D%E4%B8%8B%E6%B3%95)  
重みを少しずつ更新して勾配が最小になる点を探索するアルゴリズム。  
ディープニューラルネットワークの学習では、「局所最適解が求められればそれなりに誤差の値は小さくなるだろうから、それで妥協しよう」というスタンスに立つ。

  - 局所最適解  
    園周辺では誤差の値は小さいが、最小値を実現するわけではない解
  - 大局的最適解  
    誤差の値を最も小さくする解
  - 停留点  
    局所最適解でも大局的最適解でもないが、勾配が 0 になる点
  - 鞍点（あんてん）  
    停留点のうち、ある方向から見ると極小値だが、別の方向から見ると極大値になる点

- [誤差関数](https://ja.wikipedia.org/wiki/%E8%AA%A4%E5%B7%AE%E9%96%A2%E6%95%B0)  

- エポック  
1エポックとは、学習において訓練データをすべて使い切ったときの回数に対応する。
（訓練データを何度学習に用いたか）

- イテレーション  
  重みを何度更新したか

- SGD (確率的勾配降下法)  
無作為に選びだしたデータ（ミニバッチ）に対して行う勾配降下法。  
訓練データ1つに対して、重みを1回更新する（データ１つごとにイテレーションが増える）  
関数の形状が等方向的でないと非効率な経路で探索することが欠点、

- ミニバッチ勾配降下法  
ミニバッチに含まれるすべてのデータについて誤差の総和を計算し、その総和を小さくするように重みを1回更新する。  
ミニバッチは、いくつかの訓練データからランダムにサンプリングした小さなデータの集まり。

- 勾配降下法  
訓練データすべての誤差を計算し、重みを1回更新する（イテレーションとエポックが等しい）

- 蒸留  
大きいネットワークの入出力を小さいネットワークに再学習される手法

- Adadelta  

- 勾配消失問題  
誤差の勾配を逆伝播する過程において、勾配の値が消出し入力層付近での学習が進まなくなるディープニューラルネットワーク特有の現象。層が深いほど起こりやすい。  
活性化関数が何度も作用することで勾配が小さくなりすぎてしまうことが原因とされる。

## 最適化

- Momentum  
ボールが地面を転がるように、損失関数上での今までの動きを考慮することで SG Dの振動を抑える手法

- AdaGrad  
勾配降下法の学習率に関する手法。  
パラメータの要素ごとに適応的に学習係数を調整しながら学習を行う手法。

- RMSProp  
AdaGrad は学習雨を進めれば進めるほど、更新度合いは小さくなり、無限に学習すると、更新量は 0 になる。この問題を改善した手法が、RMSPop。  
過去のすべての勾配を均一に加算していくのではなく、過去の勾配を徐々に忘れて新しい勾配の情報が大きく反映されるように加算する手法。

- Adam  
2015年に提案された、直感的には、Momentum と　AdaGrad を融合した手法。  
先の2つの手法の利点を組み合わせることで、効率的にパラメータ空間を探索することが期待できる。  
ハイパーパラメータの補正が行われていることも特徴。

## テクニック

- ドロップアウト  
重み更新の際に一定の割合でランダムに枝を無効化する手法。単純だが効果が高い。  
アンサンブル学習と近い関係にある。

- early stopping  

- 正規化  

- 標準化  

- 白色化  

- バッチ正規化  


## CNN: 畳み込みニューラルネットワーク

特に画像認識に応答するために改良されたディープニューラルネットワーク。  
自動運転技術など、非常に広く応用されている。

従来のシグモイド関数のような活性化関数では、層が深くなるにつれ勾配が小さくなってくのでうまく学習ができないので、勾配消失問題を解決した ReLU関数を用いる。

### 処理の流れ

1. 畳み込み層  
フィルタを用いて積和演算 + 活性化関数の作用を行う層。  
元の画像の特徴が抽出された小さな画像である「特徴マップ」に変換される。

2. プーリング層  
畳み込み層から「特徴マップ」を受け取り、平均値、最大値を用いてサブサンプリングを行う層。  
平均プーリング、最大プーリングによって更に小さな画像に変換される。

3. 全結合層  
プーリング層から出力された画像データを、縦横に並んだ2次元データから、一列に並べたフラットな1次元データに変換する出力層

### 手法

- LeNet  
1988年に提案された、手書き数字認識を行うネットワーク。  
シグモイド関数を使用して、サンプリングによって中間データのサイズ縮小を行っている。  
初めての CNN。

- AlexNet  
2012年の ILSVRC でトロント大学のジェフリー・ヒントン率いるチームが用いた手法。 
  - 活性化関数に ReLU を使用
  - LRN (Local Response Noralization) という、局所的正規化を行う層を用いる
  - ドロップアウトを使用する

- maxプーリング  

- avgプーリング  

- データ拡張  

- VGG  
畳み込み層とプーリング層から構成される基本的な CNN。  
重みのある層を全部で16層まで重ねてディープにしている。  
3x3 の小さなフィルターによる畳み込み層を連続して行っている点が特徴。

- GoogLeNet  
基本的には CNN と同じ構成で、ネットワークが縦方向の深さだけでなく、横方向にも深さ（広がり）を持っているのが特徴。  
横方向の幅は「インセプション構造」と呼ばえる。  

- Skip connection  
層を飛び越えた結合

- 転移学習  
学習済みのネットワークを利用して新しいタスクの識別に利用すること

## RNN: リカレントニューラルネットワーク

時系列データにおいて、ある時間的に近接した要素同士は影響を与え合う可能性が高いが、時間的に遠く離れた要素が影響を与えることは少ない。  
この性質を使えば、パラメータの数を減らすことができる。これが RNN である。

時系列データを入力して、データから時間依存性を学習できるモデル。  
内部に閉路（行って戻ってくる経路）を持つニューラルネットワーク。  
RNN は過去の情報を保持できるため、過去の入力を参考に「時系列データの次の時点での値」を予測する。  
自然言語処理への応用が盛んで、機械翻訳技術などに応用されている。

- 入力重み衝突  

- 出力重み衝突  

- BPTT (Backpropagation Through Time)  
RNN を順伝播型ネットワークに置き換えて誤差逆伝播法を適用する手法

- CTC  
入出力間で系列長が違う場合のニューラルネットワークを用いた分類法

- LSTM (Long Short-Term Memory)  
遠い過去の入力を現在の出力に反映する手法

- seq2seq  
時系列データを入力・処理し、時系列データを出力するモデル。  
代表的な応用として入力と出力を異なる言語列とする翻訳が実現できる。  
これは NMT（ニューラル機械翻訳）と呼ばれ、従来の SMT（統計的機械翻訳）よりも大幅に性能が向上している。

- GRU (Gated Recurrent Unit)  

- Bidirectional RNN  
LSTM を2つ組み合わせることで、未来から過去方向も含めて学習できるモデル

- Sequence-to-Sequence  
入力が時系列なら出力も時系列で予測する。自然言語処理を中心に研究されている分野。

- RNN Encoder–Decoder

- Attention  
過去の時点それぞれの重みを学習することで、時間の重みをネットワークに組み込む。

## 深層強化学習

システムが「状態」を定義し、試行錯誤を重ねながら、自動的に報酬を最大化する「方策」を見つけることができる。  
さらに探索による先読みを組み合わせることで、AlphaGo（碁）の躍進につながった。

- 強化学習  
行動を学習する仕組み。目的とする報酬（スコア）を最大化するためにはどのような行動をとっていけばいいかを学習していく。  
機械学習では、想定する「状態」の数が非常に多くなったり、人による「状態」の想定に限界があったりした。

- [BRETT](https://engineering.berkeley.edu/brett/)  
カリフォルニア大学バークレー後が開発している、ディーブラーニングと強化学習を組み合わせたロボット。  
報酬の設定を変更すれば、異なる動作を学習することができる。  
一旦学習した内容はコピーして、同じタイプのロボットであれば同じように動かすことができる。

- Q学習

- [DQN (Deep Q-Network)](https://ja.wikipedia.org/wiki/DQN_(%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF))  
DeepMind が考案した、Q学習の行動価値関数を、深い構造を持ったニューラルネットワークで置き換えたモデル。  
アタリ社のゲームを学習された例では、49ゲームのうち29ゲームで、人間並、あるいはそれ以上のスコアを出した。

## 深層生成モデル

ディーブラーニング技術は、識別や回帰だけでなく、これまで存在していなかったデータ、例えば架空の画像の生成にも利用できる。  
一般に「生成モデル」と呼ばれるモデルを使うことで、AI 技術による「創作」が可能となる。  
ディープニューラルネットワークを使った生成モデルは「深層生成モデル」と呼ばれる。

- WaveNet  

- 生成モデル  

- VAE (変分オートエンコーダ)  
オートエンコーダの中間層の圧縮された特徴表現の数値を確率分布に従うように変更し、さらにエンコーダの出力とデコーダーの入力をこれにあわせて変更したのもの。  
確率分布に従うことで、圧縮された特徴表現の数値を変動させ、デコーダーの所期の性能（いろいろな猫の画像の生成）を達成できる。

- GAN (敵対的生成ネットワーク)  
2014年にイアン・グッドフェローらによって発表された、生成ネットワークと識別ネットワークからなる教師なし学習法。  
トレーニングに利用したデータに類似した出力を生成できるため、希少データの水増しや、作風をまねた絵画や楽曲の生成など、様々な応用が進められている。

  - 生成ネットワーク  
    ランダムノイズベクトルから入力データのレプリカを作ろうとする
    訓練データと同じようなデータを生成する

  - 識別ネットワーク  
    そのデータが訓練データから来たものか、生成ネットワークから来たものかを識別する

- DCGAN (Deep Convolutional GAN)  

## GNN: グラフニューラルネットワーク

グラフ構造（データ間のつながりを持った構造）のデータを入力とするニューラルネットワーク。  
GNN やオートエンコーダ、RNN を構築することができるため、広範囲の応用が可能。  
分子構造の予測や自然言語処理などへの応用がある。
